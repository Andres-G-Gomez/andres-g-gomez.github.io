---
layout: page
title: Document Classification
description: 
img: assets/img/2_project/sdg.png
importance: 2
category: Academic
pdf_link_text: "full paper"
pdf_file_path: "assets/pdf/project_submission.pdf"
---
## <u>Project Objectives</u>
In this project, we conduct a comparative study of four prominent machine learning algorithms — Multinomial Naïve Bayes (MNB), Support Vector Machine (SVM), Logistic Regression (LR), and Random Forest (RF) — tailored for text classification on the Open Software Development Governance - Code Dataset (OSDG-CD). Additionally, we identified the key words corresponding to each class. We also compared our results with other models such as BERT and Label Powerset with SVM, and discussed the advantages and disadvantages of these models in the [{{ page.pdf_link_text }}]({{ page.pdf_file_path | relative_url }}){:target="_blank"}. 


## <u>Dataset Overview</u>
<div class="container text-center">
        {% include figure.html path="assets/img/2_project/sdg_goals.png" title="example image" class="img-fluid d-block mx-auto w-25 w-md-40 w-lg-60" %}
</div>
<div class="caption">
    The United Nations introduced the Sustainable Development Goals (SDG) in 2015, urging global participation in addressing five crucial domains by 2030: people, planet, prosperity, peace, and partnership. Image courtesy of the United Nations. 
</div>

With vast amounts of data being generated by the United Nations and outside organizations daily, automatic systems that utilize machine learning and natural language processing can dramatically reduce the time is takes to track the progress made in achieving the SDGs. This work underscores the potential of text classification and keyword identification techniques in accelerating the analysis of UN documents related to the SDGs.

<div class="container text-center">
        {% include figure.html path="assets/img/2_project/freq.jpg" title="example image" class="img-fluid d-block mx-auto w-50 w-md-75 w-lg-100" %}
</div>

Open Software Development Governance - Code Dataset (OSDG-CD) 
- 30,000 text excerpts over 15 SDGs
- Average 90 words in length
- Imbalanced classes
- Respective ‘agreement’ score


## <u>Methods</u>

### Document Classification Models 
- **Multinomial Naïve Bayes (MNB)**: This model is a variant of Naïve Bayes tailored for classification with discrete features, commonly used in text classification tasks where features represent the frequency of words.
- **Support Vector Machine (SVM)**: SVM is a supervised learning model that finds the optimal hyperplane which maximizes the margin between different classes in a high-dimensional space, effective in both linear and non-linear classification tasks.
- **Logistic Regression (LR)**: Logistic Regression is a statistical model that estimates the probability of a binary outcome based on one or more predictor variables, using a logistic function to model the relationship.
- **Random Forest (RF)**: Random Forest is an ensemble learning method that builds multiple decision trees during training and outputs the mode of their predictions for classification or the mean prediction for regression, improving accuracy and control over-fitting.


### Feature Extraction Methods
- **TF-IDF (Term Frequency-Inverse Document Frequency)**: converts text into numerical vectors by weighing term frequency against inverse document frequency, highlighting important terms while reducing the impact of common words.
- **Count Vectorizer**: a text feature extraction technique that converts a collection of text documents into a matrix of token counts, representing the frequency of each word in the corpus. This numerical representation is useful for feeding text data into machine learning models.


### Training Setup
The hyperparameter tuning process involves exploring various settings to optimize model performance. Key hyperparameters include:
- Alpha values (for MNB)
- C values (for SVM and LR)
- Max depth (for RF)
- min_df (for TF-IDF)
  

To evaluate the impact of different training data strategies, three scenarios were assessed:
- Equal sample weights
- Agreement as a feature
- Weighing samples by agreement


## <u>Results</u>
### Document Classification
This work evaluates the text classification performance of MNB, SVM, LR, and RF, focusing on overall accuracies and top-3 accuracies. NLP feature extraction techniques, specifically TF-IDF and count vectorizer, are compared, with TF-IDF chosen for its ability to provide more generalizable features. 
 
<div class="row">
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.html path="assets/img/2_project/table1.JPG" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm-6 mt-3 mt-md-0">
        {% include figure.html path="assets/img/2_project/table2.JPG" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    
    Table 1 (left):Validation accuracy for SVM, MNB, LR, and RF. The top 3 accuracy is also shown for the latter 3 algorithms. Table 2 (right): Test set accuracies for SVM, MNB, LR, and RF. The top 3 accuracy is also shown for the latter 3 algorithms.
</div>

In Table 1, we see that SVM obtained the highest validation accuracy, followed closely by LR. We are unable to obtain a top 3 accuracy for SVM because it lacks a probabilistic interpretation. Of MNB, LR, and RF, LR had the highest top 3 accuracy on the validation set. In Table 2, we can observe the generalization of each model to the test set. LR obtained both the highest overall accuracy and top 3 accuracy on the test set. It is important to observe the top k accuracies because some of the SDGs are quite intertwined.

<div class="container text-center">
        {% include figure.html path="assets/img/2_project/table3.JPG" title="example image" class="img-fluid d-block mx-auto w-50 w-md-75 w-lg-100" %}
</div>
<div class="caption text-center">
    Table 3: Precision, Recall, F1-score, and overall accuracy for the LR model evaluated on the test set.
</div>

In Table 3, we show the Precision, Recall, and F1-score for the LR model evaluated on the test set. We see that the model very well on SDG 3 and quite poorly on SDG 8 and 10, as observed by the F1-score. The model obtains the lowest precision for SDG 8. 


### Keyword Identification
The second task involved determining the key words for each class. In this dataset, we are provided documents for 15 different SDGs. Keyword extraction allows us to identify the most important words or phrases in a corpus. By separating the documents into their respective classes and implementing TF-IDF, we were able to identify the keywords for each class. We listed the top 20 words for each class within the paper, and show the results for three goals below:

I.	No Poverty
- poverty, income, countries, children, social, poor, child, households, cent, household, deprivation, people, growth, rates, development, data, economic, population, employment, health

II.	Zero Hunger
- food, agricultural, countries, production, prices, land, price, farmers, agriculture, support, trade, development, policy, rural, market, policies, growth, use, farm, world

VIII.	Decent Work and Economic Growth
- employment, labour/labor, workers, work, countries, job, education, OECD, unemployment, growth, market, social, sector, economic, youth, policy, income, training, time, development


## <u>Conclusion</u>

This project evaluated text classification and keyword identification techniques for the Sustainable Development Goals (SDGs). By comparing machine learning algorithms like MNB, SVM, LR, and RF, alongside feature extraction methods like TF-IDF and Count Vectorizer, we found SVM achieved the highest validation accuracy, while LR performed best on the test set. Our keyword analysis provided valuable insights into thematic words for specific SDGs, showcasing the potential of these techniques in accelerating SDG-related analysis.
