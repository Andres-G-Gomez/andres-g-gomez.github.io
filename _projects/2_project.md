---
layout: page
title: SGD Text Classification 
description: 
img: assets/img/sdg.png
importance: 2
category: Academic
pdf_link_text: "paper"
pdf_file_path: "assets/pdf/project_submission.pdf"
---

In this project, I present a comparative study of four well known machine learning algorithms, Multinomial Naïve Bayes (MNB), Support Vector Machine (SVM), Logistic Regression (LR), and Random Forest (RF), for text classification on the Open Software Development Governance - Code Dataset (OSDG-CD). Additionally, I determined the key words for each class and evaluated the performance of each algorithm on the task of SDG classification. This comparative study showed promising results, with SVM achieving the highest accuracy of 89.4%. I also compared our results with other models such as BERT and Label Powerset with SVM, and discussed the advantages and disadvantages of these models. 

The United Nations' Sustainable Development Goals (SDGs) are a set of 17 broad goals that seek to address some of the world's most urgent economic, social, and environmental issues. Achieving these goals requires a joint effort from governments, civil society organizations, and the private sector. With vast amounts of data being generated by the United Nations and outside organizations daily, automatic systems that utilize machine learning and natural language processing can dramatically reduce the time is takes to track the progress made in achieving the SDGs. This work underscores the potential of text classification and keyword identification techniques in accelerating the analysis of UN documents related to the SDGs. These methods can effectively allow for improved monitoring of the progress made towards meeting the SDGs and contribute towards the goal of a more sustainable future.

The Open Software Development Governance - Code Dataset (OSDG-CD) contains over 30,000 text excerpts gathered by thousands of volunteers from a majority of the UN Member States. The excerpts are of paragraph length and are derived from publicly available documents [1]. Roughly 3,000 of these documents are from UN-related sources. These documents are labeled (i.e. have associated SDGs) and are roughly 90 words in length. 

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
        {% include figure.html path="assets/img/table1.JPG" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        {% include figure.html path="assets/img/table2.JPG" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Table 1 (left):Validation accuracy for SVM, MNB, LR, and RF. The top 3 accuracy is also shown for the latter 3 algorithms. Table 2 (right): Test set accuracies for SVM, MNB, LR, and RF. The top 3 accuracy is also shown for the latter 3 algorithms.
</div>

In Table 1, we see that SVM obtained the highest validation accuracy, followed closely by LR. We are unable to obtain a top 3 accuracy for SVM because it lacks a probabilistic interpretation. Of MNB, LR, and RF, LR had the highest top 3 accuracy on the validation set. In Table 2, we can observe the generalization of each model to the test set. LR obtained both the highest overall accuracy and top 3 accuracy on the test set. It is important to observe the top k accuracies because some of the SDGs are quite intertwined.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/table3.JPG" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Table 3: Precision, Recall, F1-score, and overall accuracy for the LR model evaluated on the test set.
</div>

In Table 3, we show the Precision, Recall, and F1-score for the LR model evaluated on the test set. We see that the model very well on SDG 3 and quite poorly on SDG 8 and 10, as observed by the F1-score. The model obtains the lowest precision for SDG 8. In the following section, we show the top 20 keywords as ranked by the TF-IDF score, which may provide insights into the model’s performance on these classes. 


The second task involved determining the key words for each class. In this dataset, we are provided documents for 15 different SDGs. Keyword extraction allows us to identify the most important words or phrases in a corpus. By separating the documents into their respective classes and implementing TF-IDF, we were able to identify the keywords for each class. We listed the top 20 words for each class within the [{{ page.pdf_link_text }}]({{ page.pdf_file_path | relative_url }}){:target="_blank"}. 


{% raw %}
{% endraw %}
